{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cce77b-4373-4f5b-b56c-662c5d5a9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 导入依赖库\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 2. 加载 bge-m3 模型（自动下载缓存，国内可配置镜像）\n",
    "# model1 = SentenceTransformer(\"baai/bge-m3\")\n",
    "# model.max_seq_length = 5120  # 设置文本最大长度\n",
    "\n",
    "# 1. 加载模型（自动下载并缓存）\n",
    "model_name = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "# model_name = \"Qwen/Qwen3-Embedding-4B\"\n",
    "# model_name = \"Qwen/Qwen3-Embedding-8B\"\n",
    "# model_name = \"baai/bge-m3\"\n",
    "\n",
    "model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "# model = SentenceTransformer(\"Qwen/Qwen3-Embedding-8B\")\n",
    "model.max_seq_length = 5120  # 设置最大文本长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cf1df-7aba-48c7-a63a-1fbf271058c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"  # 国内用户加速模型下载\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.byteintl.com\"  # 国内用户加速模型下载\n",
    "\n",
    "def load_md_as_text(file_path, encoding='utf-8'):\n",
    "    \"\"\"基础函数：读取 MD 文件为纯文本（带异常处理）\"\"\"\n",
    "    file_path = os.path.abspath(os.path.normpath(file_path))\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"文件不存在：{file_path}\")\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise IsADirectoryError(f\"路径不是文件：{file_path}\")\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as f:\n",
    "            return f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        raise UnicodeDecodeError(f\"编码错误！尝试指定 encoding='gbk'，文件：{file_path}\")\n",
    "        \n",
    "def split_text_with_overlap(text, chunk_size=1000, overlap=300):\n",
    "    \"\"\"\n",
    "    按指定长度分割文本，保留重叠部分\n",
    "    :param text: 待分割的纯文本\n",
    "    :param chunk_size: 每个片段的长度（默认 1000）\n",
    "    :param overlap: 片段间重叠长度（默认 300）\n",
    "    :return: 分割后的片段列表\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    # 校验参数合理性（避免负数/零）\n",
    "    chunk_size = max(int(chunk_size), 1)\n",
    "    overlap = max(int(overlap), 0)\n",
    "    if overlap >= chunk_size:\n",
    "        raise ValueError(\"重叠长度不能大于等于片段长度！\")\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "    \n",
    "    while start < text_length:\n",
    "        # 计算当前片段的结束位置\n",
    "        end = start + chunk_size\n",
    "        # 截取片段（最后一个片段直接取到末尾）\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        # 计算下一个片段的起始位置（避免超出文本长度）\n",
    "        next_start = start + (chunk_size - overlap)\n",
    "        # 若下一个起始位置超过文本长度，直接退出（最后一个片段已添加）\n",
    "        if next_start >= text_length:\n",
    "            break\n",
    "        # 更新起始位置\n",
    "        start = next_start\n",
    "    \n",
    "    return chunks\n",
    "    \n",
    "\n",
    "\n",
    "# 2. 生成 Embedding（支持单条/批量，默认归一化）\n",
    "text1 = \"Elasticsearch 向量搜索使用 HNSW 算法\"\n",
    "embedding1 = model.encode(text1, normalize_embeddings=True)\n",
    "embedding_dim = embedding1.shape[0]\n",
    "print(f\"单条文本 Embedding 维度：{embedding1.shape}\")  # (1024,)\n",
    "\n",
    "# 批量生成\n",
    "query=\"speed of light\"\n",
    "texts = [\n",
    "    (\"Section 1\", \"Science is a powerful tool that allows humans to observe, understand, and explain the world around them. Through centuries of inquiry and experimentation, scientists have uncovered countless facts about the universe, many of which shape the way we live today. Below are some fascinating scientific facts that highlight the beauty and complexity of nature.\"),\n",
    "    (\"Section 2\",\"\"\"# The Universe Is Expanding\n",
    "\n",
    "One of the most profound discoveries in modern astronomy is that the universe is constantly expanding. In 1929, Edwin Hubble observed that galaxies are moving away from each other, implying that the universe had a beginning. This discovery laid the foundation for the Big Bang theory, which suggests that the cosmos began around 13.8 billion years ago.\n",
    "\"\"\"),\n",
    "    (\"Section 3\",\"\"\"# DNA: The Blueprint of Life\n",
    "Deoxyribonucleic acid (DNA) contains the genetic instructions for building and maintaining life. Every living organism on Earth shares this molecular code, though arranged differently. A surprising fact is that humans share about 60% of their DNA with bananas, highlighting the interconnectedness of life on Earth.\n",
    "\"\"\"),\n",
    "    (\"Section 4\",\"\"\"# The Human Brain’s Complexity\n",
    "The human brain is considered the most complex structure known in the universe. It contains around 86 billion neurons, each connected to thousands of others, creating trillions of synaptic connections. These networks enable thought, memory, emotions, and consciousness. Remarkably, the brain uses about 20% of the body’s energy, even though it accounts for only 2% of body mass.\"\"\"),\n",
    "    (\"Section 5\",\"\"\"# Water Is Unique\n",
    "Water has extraordinary properties that make life possible. Unlike most substances, water expands when it freezes, causing ice to float. This prevents bodies of water from freezing solid and allows aquatic life to survive under ice sheets. Water is also a universal solvent, enabling countless chemical reactions within cells.\"\"\"),\n",
    "    (\"Target Section\",\"\"\"# The Speed of Light\n",
    "Light travels at approximately 299,792 kilometers per second (186,282 miles per second) in a vacuum. To put this into perspective, light from the Sun takes just over eight minutes to reach Earth. This incredible speed makes light the fastest thing in the universe and serves as a fundamental constant in physics.\"\"\"),\n",
    "    (\"Section 7\",\"\"\"# The Earth’s Protective Atmosphere\n",
    "Earth’s atmosphere shields us from harmful radiation and space debris. The ozone layer, in particular, absorbs most of the Sun’s ultraviolet rays, protecting living organisms from genetic damage. Without the atmosphere, life as we know it would not exist.\"\"\"),\n",
    "    (\"Section 8\",\"\"\"# Evolution Shapes Life\n",
    "Charles Darwin’s theory of evolution by natural selection remains one of the most important scientific discoveries. Over millions of years, species adapt to their environments, resulting in the incredible diversity of life we see today. For example, whales evolved from land-dwelling mammals that returned to the sea about 50 million years ago.\"\"\"),\n",
    "    (\"Section 9\",\"\"\"# Conclusion\n",
    "Scientific facts remind us that the universe is vast, life is interconnected, and human knowledge continues to grow. From the tiniest molecule of DNA to the largest galaxies, science reveals the underlying order and beauty of existence. As we uncover more truths, our appreciation of the natural world deepens, inspiring innovation, curiosity, and respect for life.\"\"\")\n",
    "]\n",
    "# 添加英文摘要\n",
    "texts.append((\"Summary\",\"- Science serves as a pivotal tool for humans to observe, comprehend, and explain the natural world. Centuries of scientific inquiry and experimentation have yielded countless discoveries that shape modern life, revealing nature’s beauty and complexity through fascinating facts. This work highlights key scientific insights: the universe is continuously expanding (a 1929 discovery by Edwin Hubble that underpins the Big Bang theory, dating the cosmos to 13.8 billion years ago); DNA, the universal genetic blueprint of life, shows unexpected connections (e.g., humans share 60% of their DNA with bananas); the human brain—with 86 billion neurons and trillions of synaptic connections—uses 20% of the body’s energy despite accounting for only 2% of its mass; water’s unique properties (expanding when freezing, acting as a universal solvent) enable life on Earth; light travels at 299,792 km/s in a vacuum, the fastest speed in the universe, with sunlight reaching Earth in over 8 minutes; Earth’s atmosphere, particularly the ozone layer, shields life from harmful radiation and space debris; and Darwin’s theory of evolution by natural selection explains the diversity of life (e.g., whales evolved from land mammals 50 million years ago). In conclusion, these scientific facts underscore the universe’s vastness, the interconnectedness of life, and the ongoing growth of human knowledge, deepening our appreciation for the natural world and inspiring curiosity and innovation.\"))\n",
    "# 添加关键词\n",
    "texts.append((\"Keywords\", \"\"\"DNA\n",
    "Science\n",
    "Scientific Facts\n",
    "Universe\n",
    "Human Brain\n",
    "Water\n",
    "Speed of Light\n",
    "Earth’s Atmosphere\n",
    "Evolution\n",
    "Natural World\"\"\"))\n",
    "     \n",
    "\n",
    "                 \n",
    "# 1. 读取 MD 文件（支持相对/绝对路径，中文编码可指定 encoding='gbk'）\n",
    "md_text = load_md_as_text(\"Scientific Facts Test Doc.md\", encoding='utf-8')\n",
    "\n",
    "texts.append((\"Target doc\", md_text))\n",
    "\n",
    "# 2. 分割文本（1000 字符/片段，300 字符重叠）\n",
    "chunks = split_text_with_overlap(\n",
    "    text=md_text,\n",
    "    chunk_size=1000,\n",
    "    overlap=300\n",
    ")\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    texts.append((f\"Chunk {idx}\", chunk))\n",
    "\n",
    "# dump texts to json\n",
    "with open('texts.json', 'w') as f:\n",
    "    json.dump(texts, f)\n",
    "    \n",
    "# 4. 生成 Embedding（Query + 所有 Texts）\n",
    "query_embedding = model.encode(query, normalize_embeddings=True).reshape(1, -1)  # (1, 1024)\n",
    "texts_embeddings = model.encode([t[1] for t in texts], normalize_embeddings=True)  # (n, 1024)，n 是 texts 长度\n",
    "print(f\"批量 Embedding 形状：{texts_embeddings.shape}\")  # (10, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a85ba-8873-454b-a21a-7d8bb01f42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv add matplotlib seaborn ipywidgets jupyterlab-widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cb8cb-ce23-4d39-92d2-dde229299bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontManager, FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 获取所有系统字体\n",
    "fm = FontManager()\n",
    "all_fonts = {f.name: f.fname for f in fm.ttflist}  # 字体名称: 字体文件路径\n",
    "\n",
    "# 筛选支持中文的字体（关键词匹配）\n",
    "chinese_keywords = ['Chinese', 'CJK', '中', '华', '宋', '黑', '楷', '微软', 'YaHei', 'Sim', 'Heiti']\n",
    "available_chinese_fonts = {}\n",
    "for font_name, font_path in all_fonts.items():\n",
    "    if any(keyword in font_name or keyword in font_path for keyword in chinese_keywords):\n",
    "        available_chinese_fonts[font_name] = font_path\n",
    "\n",
    "print(\"系统真实可用的中文字体：\")\n",
    "for name, path in available_chinese_fonts.items():\n",
    "    print(f\"- 字体名称：{name}\")\n",
    "    print(f\"  文件路径：{path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d7e673-a77c-4d29-8215-e3a8dd37f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 计算 Query 与每个 Text 的余弦相似度\n",
    "similarities = cosine_similarity(query_embedding, texts_embeddings)[0]  # (n,)，每个元素是相似度得分（0~1）\n",
    "\n",
    "# 6. 整理数据为 DataFrame（方便可视化）\n",
    "df = pd.DataFrame({\n",
    "    \"文本内容\": [t[0] for t in texts],\n",
    "    \"与 Query 相似度\": similarities\n",
    "}).sort_values(\"与 Query 相似度\", ascending=False)  # 按相似度降序排序\n",
    "\n",
    "\n",
    "# 解决中文显示问题（根据系统选择对应字体名称）\n",
    "plt.rcParams['font.sans-serif'] = [\n",
    "    'SimHei',      # Windows 系统（黑体）\n",
    "    'Microsoft YaHei',  # Windows 备选（微软雅黑）\n",
    "    'Heiti TC',    # macOS 系统（黑体-繁体，兼容简体）\n",
    "    'Arial Unicode MS',# macOS 备选\n",
    "    'WenQuanYi Zen Hei',# Linux 系统（文泉驿正黑）\n",
    "    'DejaVu Sans'  # 兜底：若以上都没有，用默认支持部分字符的字体\n",
    "]\n",
    "# 解决负号显示为方块的问题（可选）\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 8. 绘制相似度图表（两种常用类型，选一种或都用）\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))  # 1行2列图表，总宽度16，高度6\n",
    "\n",
    "# 子图1：水平条形图（推荐，适合文本标签）\n",
    "colors = sns.color_palette(\"RdYlBu_r\", len(texts))  # 渐变颜色（红色=低相似度，蓝色=高相似度）\n",
    "bars = ax1.barh(\n",
    "    y=range(len(df)), \n",
    "    width=df[\"与 Query 相似度\"], \n",
    "    color=colors,\n",
    "    alpha=0.8\n",
    ")\n",
    "# 设置子图1标签\n",
    "ax1.set_yticks(range(len(df)))\n",
    "# ylabel 处理：取前10字符 + ...，确保标签简洁\n",
    "yticklabels = [\n",
    "    text[:10] + \"...\" if len(text) > 10 else text \n",
    "    for text in df[\"文本内容\"]\n",
    "]\n",
    "ax1.set_yticklabels(yticklabels, fontsize=10)  # 文本标签字体大小\n",
    "ax1.set_xlabel(\"余弦相似度得分（0~1，越高越相似）\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_title(f\"Query: {query}\\n文本与 Query 相似度排名,{model_name}, \", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "ax1.set_xlim(0, 1)  # x轴范围（0~1，符合相似度取值）\n",
    "\n",
    "# 在条形图上添加数值标签\n",
    "for i, (bar, score) in enumerate(zip(bars, df[\"与 Query 相似度\"])):\n",
    "    ax1.text(\n",
    "        bar.get_width() + 0.01,  # 数值在条形右侧\n",
    "        bar.get_y() + bar.get_height()/2,  # 垂直居中\n",
    "        f\"{score:.3f}\",  # 保留3位小数\n",
    "        va=\"center\", fontsize=9, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "# 子图2：折线图（展示相似度分布趋势）\n",
    "ax2.plot(\n",
    "    range(1, len(df)+1),  # x轴：排名（1~n）\n",
    "    df[\"与 Query 相似度\"], \n",
    "    marker=\"o\",  # 标记点为圆形\n",
    "    linewidth=2.5, \n",
    "    markersize=8,\n",
    "    color=\"#2E86AB\",\n",
    "    markerfacecolor=\"#A23B72\",  # 标记点填充色\n",
    "    markeredgecolor=\"white\",\n",
    "    markeredgewidth=2\n",
    ")\n",
    "# 设置子图2标签\n",
    "ax2.set_xlabel(\"文本排名（按相似度降序）\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"余弦相似度得分\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_title(\"相似度分布趋势\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "ax2.set_xticks(range(1, len(df)+1))\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 在折线图标记点添加数值\n",
    "for i, score in enumerate(df[\"与 Query 相似度\"]):\n",
    "    ax2.text(\n",
    "        i+1, score + 0.01,\n",
    "        f\"{score:.3f}\",\n",
    "        ha=\"center\", va=\"bottom\",\n",
    "        fontsize=9, fontweight=\"bold\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7)  # 黄色背景框\n",
    "    )\n",
    "\n",
    "# 调整布局，避免标签重叠\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图表（可选，保存为高清图片）\n",
    "plt.savefig(\"query_text_similarity.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n",
    "\n",
    "# 9. 打印相似度数据表格（Notebook 中展示）\n",
    "print(\"=\"*80)\n",
    "print(f\"Query: {query}, {model}, {embedding_dim}\")\n",
    "print(\"=\"*80)\n",
    "df_display = df.reset_index(drop=True)\n",
    "df_display[\"排名\"] = range(1, len(df_display)+1)\n",
    "df_display = df_display[[\"排名\", \"文本内容\", \"与 Query 相似度\"]]\n",
    "print(df_display.to_string(index=False, float_format=lambda x: f\"{x:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a1ba3-f534-428f-acaf-8ca6daa2ff50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b05e46-9ed8-41c2-b6d1-98e4054d1b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
